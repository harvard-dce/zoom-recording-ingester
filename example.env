# should only be necessary if you have multiple credential profiles
#AWS_PROFILE=

# tags that will be assigned to the cfn stack and all resources under it
# space-separated key/value pairs, like so:
# Key=key1,Value=value1 Key=key2,Value=value2
STACK_TAGS=Key=Project,Value=MH Key=OU,Value=DE

# alternate name for the cfn stack - required
STACK_NAME=

# s3 bucket to store packaged lambda code
LAMBDA_CODE_BUCKET=

# where cloudwatch alarm notifications will get sent
NOTIFICATION_EMAIL=

# Email address associated with a Zoom administrative level account
# This is used to get a token to authenticate downloads
ZOOM_ADMIN_EMAIL=

ZOOM_API_BASE_URL=
ZOOM_API_KEY=
ZOOM_API_SECRET=

# URL and API auth for the target opencast cluster
OC_CLUSTER_NAME=
OPENCAST_API_USER=
OPENCAST_API_PASSWORD=

# id of series to receive ingests in the absence of a zoom meeting -> series mapping
# this is meant for testing/dev only. If you set this to a valid Opencast series id
# then any recording that doesn't match something in the class schedule data will
# be ingested into that default series id.
DEFAULT_SERIES_ID=

# Opencast 5.x:
#     publisher = producer username or email
#     no contributor
# When the publisher of a series cannot be determined via an
# /otherpubs/epidodedefault lookup, the Opencast workflow notifications will go
# to this address. If this is left empty the notifications will go to the
# NOTIFICATION_EMAIL address.
DEFAULT_PUBLISHER=
# These settings will override the Opencast lookup of publisher and contributor
# for a series.
OVERRIDE_PUBLISHER=
OVERRIDE_CONTRIBUTOR=

# 5x clusters: "dce-int-production-zoom" / "multipart/chunked+source"
OC_WORKFLOW=
OC_FLAVOR=

# controls how many download queue messages will be processed (not ingested!) per
# invocation of the downloader function
DOWNLOAD_MESSAGES_PER_INVOCATION=10

# controls how far in minutes the schedule matching will allow for start/end times
BUFFER_MINUTES=30

# videos shorter than this many minutes will be ignored
MINIMUM_DURATION=2

# Python pytz timezone
LOCAL_TIME_ZONE=US/Eastern

# The Lambda Function alias that points to the "live" version of the function
LAMBDA_RELEASE_ALIAS=live

LOG_NOTIFICATIONS_FILTER_LOG_LEVEL=ERROR

# Password for the opencast mysql root user
# You can get this from the cluster config of the cluster being ingested to
# The invoke tasks will find the actual RDS endpoint via an aws lookup
OC_DB_PASSWORD=

# the uploader will query opencast for the number of currently running track uploads
# if it is greater than this number the uploader will abort (leaving the upload in the queue)
OC_TRACK_UPLOAD_MAX=5

# These (comma-separated) IPs will be included in the APIs resource policy
# Only requests coming from these IPs will be allowed to exec the on-demand ingest endpoint
# Assuming the Opsworks cluster is up-to-date, these should be the same ips listed
# in the cluster config's "vpn_ips" list.
INGEST_ALLOWED_IPS=
